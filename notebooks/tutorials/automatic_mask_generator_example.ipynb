{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa21d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0041e",
   "metadata": {},
   "source": [
    "# Automatically generating object masks with SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289bb0b4",
   "metadata": {},
   "source": [
    "Since SAM can efficiently process prompts, masks for the entire image can be generated by sampling a large number of prompts over an image. This method was used to generate the dataset SA-1B. \n",
    "\n",
    "The class `SamAutomaticMaskGenerator` implements this capability. It works by sampling single-point input prompts in a grid over the image, from each of which SAM can predict multiple masks. Then, masks are filtered for quality and deduplicated using non-maximal suppression. Additional options allow for further improvement of mask quality and quantity, such as running prediction on multiple crops of the image or postprocessing masks to remove small disconnected regions and holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\n",
    "\"\"\"\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b71431",
   "metadata": {},
   "source": [
    "## Environment Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5a78f",
   "metadata": {},
   "source": [
    "If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_colab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe300fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install opencv-python matplotlib\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "    \n",
    "    !mkdir images\n",
    "    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
    "        \n",
    "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bc687",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560725a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c41445",
   "metadata": {},
   "source": [
    "## Example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a463bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/data/sample_data'\n",
    "grayscale_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if 'grayscale' in f]\n",
    "color_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if 'color' in f]\n",
    "print(grayscale_files)\n",
    "print(color_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad354922",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c2824a",
   "metadata": {},
   "source": [
    "## Automatic mask generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ef74c5",
   "metadata": {},
   "source": [
    "To run automatic mask generation, provide a SAM model to the `SamAutomaticMaskGenerator` class. Set the path below to the SAM checkpoint. Running on CUDA and with the default model is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"../../data/models/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1ea21",
   "metadata": {},
   "source": [
    "To generate masks, just run `generate` on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391771c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = mask_generator.generate(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a1a39",
   "metadata": {},
   "source": [
    "Mask generation returns a list over masks, where each mask is a dictionary containing various data about the mask. These keys are:\n",
    "* `segmentation` : the mask\n",
    "* `area` : the area of the mask in pixels\n",
    "* `bbox` : the boundary box of the mask in XYWH format\n",
    "* `predicted_iou` : the model's own prediction for the quality of the mask\n",
    "* `point_coords` : the sampled input point that generated this mask\n",
    "* `stability_score` : an additional measure of mask quality\n",
    "* `crop_box` : the crop of the image used to generate this mask in XYWH format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(masks))\n",
    "print(masks[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53009a1f",
   "metadata": {},
   "source": [
    "Show all the masks overlayed on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac29c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3d6b2",
   "metadata": {},
   "source": [
    "## Automatic mask generation options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183de84e",
   "metadata": {},
   "source": [
    "There are several tunable parameters in automatic mask generation that control how densely points are sampled and what the thresholds are for removing low quality or duplicate masks. Additionally, generation can be automatically run on crops of the image to get improved performance on smaller objects, and post-processing can remove stray pixels and holes. Here is an example configuration that samples more masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68364513",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator_2 = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=32,\n",
    "    pred_iou_thresh=0.86,\n",
    "    stability_score_thresh=0.92,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcdaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks2 = mask_generator_2.generate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8473f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb702ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb041824",
   "metadata": {},
   "source": [
    "# sam_topo test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c937160",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator_2 = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=32,\n",
    "    pred_iou_thresh=0.86,\n",
    "    stability_score_thresh=0.85,\n",
    "    #crop_n_layers=1,\n",
    "    #crop_n_points_downscale_factor=2,\n",
    "    #min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b679f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks2 = mask_generator_2.generate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7693796",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b91d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531446b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_hillshade_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ef74b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d394b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_slope_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825991d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_slope_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DTM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9478c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026fc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/beach_slope_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7adc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/beach_slope_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52abf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/beach_roughness_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f538d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/beach_aspect_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ede583",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/beach_aspect_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/beach_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da82cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_hillshade_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_aspect_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_aspect_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b8b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_slope_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685938fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_slope_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/Kaibab_DSM_hillshade_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56aec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/landslide_DEM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/landslide_DEM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88df174",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/landslide_DEM_color.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/landslide_DEM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../data/data/sample_data/NYC_DEM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "masks2 = mask_generator_2.generate(image)\n",
    "print(len(masks2))\n",
    "\n",
    "image = cv2.imread('../../data/data/sample_data/NYC_DEM_grayscale.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "for mask in masks2:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image)\n",
    "    show_anns([mask])\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4052f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
